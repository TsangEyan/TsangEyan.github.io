<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>D3Lab</title>
    <link>https://TsangEyan.github.io/</link>
      <atom:link href="https://TsangEyan.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>D3Lab</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 20 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://TsangEyan.github.io/media/logo_hu7c8f66c823bc2a62619a39dc1829654e_14272_300x300_fit_lanczos_3.png</url>
      <title>D3Lab</title>
      <link>https://TsangEyan.github.io/</link>
    </image>
    
    <item>
      <title>项目例子</title>
      <link>https://TsangEyan.github.io/project/example1/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/project/example1/</guid>
      <description>&lt;p&gt;项目极简介绍（50字左右）&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;移轴摄影会拍出小人国的效果的原因：在正常情况下，景深同对焦点距离成正比，同镜头焦距长度成反比，人眼也符合这个规律，大脑在长期的训练下也默认了这个规则。移轴镜头可以改变光路，使得焦平面和感光平面不平行，只有两个平面相交的那条线附近的景物清晰，造成特殊的“浅景深”。那种看起来像模型的移轴照片多是广角远距离拍摄，在大脑的规则中，这种距离的广角视角下不可能出现浅景深，所以会产生错觉，以为这是近距离摄影。在近距离景物又比较小的话，就像是模型了。&lt;/p&gt;
&lt;p&gt;视频转载于无限飓风&lt;/p&gt;
&lt;h2 id=&#34;项目应用&#34;&gt;项目应用&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://www.bilibili.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_2bd6f1d0bb4d068a81c3218e36233825.webp 400w,
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_e474625100140e3d4d504f0bb0aad18d.webp 760w,
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://TsangEyan.github.io/media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_2bd6f1d0bb4d068a81c3218e36233825.webp&#34;
               width=&#34;760&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>课程1</title>
      <link>https://TsangEyan.github.io/courses-project/course1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/courses-project/course1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>项目例子2</title>
      <link>https://TsangEyan.github.io/project/example2/</link>
      <pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/project/example2/</guid>
      <description>&lt;p&gt;项目极简介绍（50字左右）&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;移轴摄影会拍出小人国的效果的原因：在正常情况下，景深同对焦点距离成正比，同镜头焦距长度成反比，人眼也符合这个规律，大脑在长期的训练下也默认了这个规则。移轴镜头可以改变光路，使得焦平面和感光平面不平行，只有两个平面相交的那条线附近的景物清晰，造成特殊的“浅景深”。那种看起来像模型的移轴照片多是广角远距离拍摄，在大脑的规则中，这种距离的广角视角下不可能出现浅景深，所以会产生错觉，以为这是近距离摄影。在近距离景物又比较小的话，就像是模型了。&lt;/p&gt;
&lt;p&gt;视频转载于无限飓风&lt;/p&gt;
&lt;h2 id=&#34;项目应用&#34;&gt;项目应用&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://www.bilibili.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_2bd6f1d0bb4d068a81c3218e36233825.webp 400w,
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_e474625100140e3d4d504f0bb0aad18d.webp 760w,
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://TsangEyan.github.io/media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_2bd6f1d0bb4d068a81c3218e36233825.webp&#34;
               width=&#34;760&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>课程2</title>
      <link>https://TsangEyan.github.io/courses-project/course2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/courses-project/course2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>奥利与奥斯卡</title>
      <link>https://TsangEyan.github.io/talk/example2/</link>
      <pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/talk/example2/</guid>
      <description>&lt;p&gt;奥利与奥斯卡的日常&lt;/p&gt;
  





&lt;video controls  &gt;
  &lt;source src=&#34;https://TsangEyan.github.io/talk/example2/my_video.MP4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;p&gt;awslawslawslawslawsl
awslawslawslawslawsl
视频转载于奥利与奥斯卡&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>拍摄小人国</title>
      <link>https://TsangEyan.github.io/talk/example/</link>
      <pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/talk/example/</guid>
      <description>&lt;p&gt;移轴镜头作为一种特殊的拍摄手法，经常出现在电影中&lt;/p&gt;
&lt;p&gt;移轴摄影会拍出小人国的效果的原因：在正常情况下，景深同对焦点距离成正比，同镜头焦距长度成反比，人眼也符合这个规律，大脑在长期的训练下也默认了这个规则。移轴镜头可以改变光路，使得焦平面和感光平面不平行，只有两个平面相交的那条线附近的景物清晰，造成特殊的“浅景深”。那种看起来像模型的移轴照片多是广角远距离拍摄，在大脑的规则中，这种距离的广角视角下不可能出现浅景深，所以会产生错觉，以为这是近距离摄影。在近距离景物又比较小的话，就像是模型了。&lt;/p&gt;
&lt;p&gt;视频转载于无限飓风&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>项目例子3</title>
      <link>https://TsangEyan.github.io/project/example3/</link>
      <pubDate>Sat, 02 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/project/example3/</guid>
      <description>&lt;p&gt;项目极简介绍（50字左右）&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;移轴摄影会拍出小人国的效果的原因：在正常情况下，景深同对焦点距离成正比，同镜头焦距长度成反比，人眼也符合这个规律，大脑在长期的训练下也默认了这个规则。移轴镜头可以改变光路，使得焦平面和感光平面不平行，只有两个平面相交的那条线附近的景物清晰，造成特殊的“浅景深”。那种看起来像模型的移轴照片多是广角远距离拍摄，在大脑的规则中，这种距离的广角视角下不可能出现浅景深，所以会产生错觉，以为这是近距离摄影。在近距离景物又比较小的话，就像是模型了。
视频转载于无限飓风&lt;/p&gt;
&lt;h2 id=&#34;项目应用&#34;&gt;项目应用&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://www.bilibili.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_2bd6f1d0bb4d068a81c3218e36233825.webp 400w,
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_e474625100140e3d4d504f0bb0aad18d.webp 760w,
               /media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://TsangEyan.github.io/media/project-example2_hu86461e76de838cf4b9c7f3e76a894b06_3743140_2bd6f1d0bb4d068a81c3218e36233825.webp&#34;
               width=&#34;760&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>zju夏令营</title>
      <link>https://TsangEyan.github.io/event/example/</link>
      <pubDate>Fri, 01 Jul 2022 13:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/event/example/</guid>
      <description>&lt;!-- Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [_Slides_](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
&lt;p&gt;有意保研的同学欢迎联系浙江大学 智能设计实验室 &lt;a href=&#34;https://person.zju.edu.cn/chenlq&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;陈柳青老师&lt;/em&gt;&lt;/a&gt;参加暑期实习，研究方向包括智能UI、创意设计、VR/AR/XR、交互设计与用户体验等，可在阿里巴巴兼职实习、去往帝国理工交流访学，招收对象为计算机类、设计类相关专业学生，有意向者请投简历联系陈柳青老师 chenlq@zju.edu.cn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直博生可以直接报学院的夏令营计划，截止7.1； 硕士直接参加实验室的实习&lt;/li&gt;
&lt;li&gt;夏令营与实习的对接与进度检查:
&lt;ul&gt;
&lt;li&gt;进度跟进&lt;/li&gt;
&lt;li&gt;能力考查&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>In search of an ending</title>
      <link>https://TsangEyan.github.io/post/20-12-02-icml-best-paper/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/post/20-12-02-icml-best-paper/</guid>
      <description>&lt;p&gt;Foreign private-equity barons circle a fading jewel of corporate Japan&lt;/p&gt;
&lt;p&gt;Toshiba was once synonymous with Japan’s industrial might. Of late the conglomerate, which has made everything from memory cards to nuclear reactors, has become a byword for drama. Japan’s business press writes of“Toshiba Theatre”, which began with accounting fraud a decade ago and has continued to the present day in a series of “slapstick” struggles between management and shareholders. Toshiba’s share price has underperformed domestic and foreign rivals, as well as the broaderJapanese stockmarket (see chart).The latest plot twist comes amid talk of a buy­out led by Bain Capital, an American private­equity group. This raised hopes among investors for some sort of resolution to the saga. Toshiba’s market value has risen by a quarterin the past month.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Seeing and believing</title>
      <link>https://TsangEyan.github.io/post/20-12-01-wowchemy-prize/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/post/20-12-01-wowchemy-prize/</guid>
      <description>&lt;p&gt;Tech firms are betting that “extended reality” glasses could be the next big product—and perhaps the next big platform&lt;/p&gt;
&lt;p&gt;With eyes like saucers, nine-year-old Ralph Miles slowly removes his Quest 2 headset. “It was like being in another galaxy!” he exclaims. He has just spent ten minutes blasting alien robotswith deafening laser cannons—all the while seated silently in the home-electronics section of a London department store.Sales assistants bustle around, advertising
the gear to take home today. “That would be sick!” enthuses Ralph. “Don’t get him started,” warns his dad.&lt;/p&gt;
&lt;p&gt;Children are no longer the only ones excited about “extended reality”, a category which includes both fully immersive virtual reality (vr) and augmented reality (ar), in which computer imagery is superimposed onto users’ view of the world around them. Nearly every big technology firm is rushing to develop a vr or ar headset, convinced that what has long been a niche market may be on the brink of becoming something much larger.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Seeing and believing</title>
      <link>https://TsangEyan.github.io/post/20-12-01-wowchemy-prize2/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/post/20-12-01-wowchemy-prize2/</guid>
      <description>&lt;p&gt;Tech firms are betting that “extended reality” glasses could be the next big product—and perhaps the next big platform&lt;/p&gt;
&lt;p&gt;With eyes like saucers, nine-year-old Ralph Miles slowly removes his Quest 2 headset. “It was like being in another galaxy!” he exclaims. He has just spent ten minutes blasting alien robotswith deafening laser cannons—all the while seated silently in the home-electronics section of a London department store.Sales assistants bustle around, advertising
the gear to take home today. “That would be sick!” enthuses Ralph. “Don’t get him started,” warns his dad.&lt;/p&gt;
&lt;p&gt;Children are no longer the only ones excited about “extended reality”, a category which includes both fully immersive virtual reality (vr) and augmented reality (ar), in which computer imagery is superimposed onto users’ view of the world around them. Nearly every big technology firm is rushing to develop a vr or ar headset, convinced that what has long been a niche market may be on the brink of becoming something much larger.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Seeing and believing</title>
      <link>https://TsangEyan.github.io/post/20-12-01-wowchemy-prize3/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/post/20-12-01-wowchemy-prize3/</guid>
      <description>&lt;p&gt;Tech firms are betting that “extended reality” glasses could be the next big product—and perhaps the next big platform&lt;/p&gt;
&lt;p&gt;With eyes like saucers, nine-year-old Ralph Miles slowly removes his Quest 2 headset. “It was like being in another galaxy!” he exclaims. He has just spent ten minutes blasting alien robotswith deafening laser cannons—all the while seated silently in the home-electronics section of a London department store.Sales assistants bustle around, advertising
the gear to take home today. “That would be sick!” enthuses Ralph. “Don’t get him started,” warns his dad.&lt;/p&gt;
&lt;p&gt;Children are no longer the only ones excited about “extended reality”, a category which includes both fully immersive virtual reality (vr) and augmented reality (ar), in which computer imagery is superimposed onto users’ view of the world around them. Nearly every big technology firm is rushing to develop a vr or ar headset, convinced that what has long been a niche market may be on the brink of becoming something much larger.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://TsangEyan.github.io/publication/conference-paper/</link>
      <pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>https://TsangEyan.github.io/publication/journal-article/</link>
      <pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://TsangEyan.github.io/publication/preprint/</link>
      <pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/publication/preprint/</guid>
      <description>&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code and math&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://TsangEyan.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://TsangEyan.github.io/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://TsangEyan.github.io/people/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
